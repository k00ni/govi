#!/usr/bin/env php
<?php

declare(strict_types=1);

/**
 * Read ontology information from Linked Open Vocabularies:
 *
 * https://lov.linkeddata.es/dataset/lov/
 */

use App\IndexEntry;
use quickRdf\DataFactory;
use quickRdfIo\Util;
use rdfInterface\BlankNodeInterface;
use rdfInterface\LiteralInterface;
use sweetrdf\InMemoryStoreSqlite\Store\InMemoryStoreSqlite;

use function App\isEmpty;
use function App\isUrl;
use function App\storeTemporaryIndexIntoSQLiteFile;
use function App\uncompressGzArchive;

require 'bootstrap.php';

$lovDumpUrl = 'https://lov.linkeddata.es/lov.n3.gz';

// time limit for script
\set_time_limit(3600);

echo 'ask LOV API for vocabulary list';

/*
 * 1. get a list of all vocabularies (prefix + title + URI)
 */
$url = 'https://lov.linkeddata.es/dataset/lov/api/v2/vocabulary/list';
$json = file_get_contents($url);
$entriesArr = json_decode($json, true);
$miniVocabularyIndex = [];

foreach ($entriesArr as $arr) {
    $entry = new IndexEntry('Linked Open Vocabularies', $lovDumpUrl);
    $entry->setOntologyTitle($arr['titles'][0]['value']); // TODO: handle case: multiple title entries
    $entry->setOntologyUri($arr['uri']); // TODO: handle case: multiple title entries

    $miniVocabularyIndex[$arr['uri']] = $entry;
}

/*
 * 2. Download latest LOV dump (.gz file) and uncompress it.
 *
 * We assume it contains all vocabulary meta data.
 *
 * TODO if this takes too long, use gunzip for alternatives instead.
 */
$n3Filepath = SCRIPTS_DIR_PATH.'var'.DIRECTORY_SEPARATOR.'lov.n3';

if (file_exists($n3Filepath)) {
    unlink($n3Filepath);
}

echo PHP_EOL.'uncompress .gz file';

uncompressGzArchive($lovDumpUrl, $n3Filepath);

/*
 * 3. Read N3 file (triple by triple) and for each vocabulary entry look for the latest raw data file
 * (predicate http://www.w3.org/ns/dcat#distribution).
 */
echo PHP_EOL.'read n3 dump file';

$dataFactory = new DataFactory();
$iterator = Util::parse($n3Filepath, $dataFactory, 'turtle', 'http://lov/');

$ontologyRelatedTriples = [];
$predicateWhitelist = ['http://purl.org/dc/terms/modified', 'http://www.w3.org/ns/dcat#distribution'];

// in memory store only adds 1000 triples per second, but the dump file has over 200k
// therefor collect only those which are relevant
foreach ($iterator as $quad) {
    // found vocabulary entry
    $s = $quad->getSubject()->getValue();
    if (isset($miniVocabularyIndex[$s]) && in_array($quad->getPredicate()->getValue(), $predicateWhitelist, true)) {
        // determine object type
        if ($quad->getObject() instanceof LiteralInterface) {
            $oType = 'uri';
        } elseif ($quad->getObject() instanceof BlankNodeInterface) {
            $oType = 'bnode';
        } else {
            $oType = 'literal';
        }

        $ontologyRelatedTriples[] = [
            's' => $quad->getSubject()->getValue(),
            's_type' => $quad->getSubject() instanceof BlankNodeInterface ? 'bnnode' : 'uri',
            'p' => $quad->getPredicate()->getValue(),
            'p_type' => $quad->getPredicate() instanceof BlankNodeInterface ? 'bnnode' : 'uri',
            'o' => $quad->getObject()->getValue(),
            'o_type' => $oType,
            'o_lang' => $quad->getObject() instanceof LiteralInterface ? $quad->getObject()->getLang() : '',
            'o_datatype' => $quad->getObject() instanceof LiteralInterface ? $quad->getObject()->getDatatype() : '',
        ];
    }
}

echo PHP_EOL.'found '.count($ontologyRelatedTriples).' triples for in-memory store';

$store = InMemoryStoreSqlite::createInstance();
$store->addRawTriples($ontologyRelatedTriples, 'http://lov/');

foreach ($miniVocabularyIndex as $uri => $entry) {
    // get all triples for given ontology/vocabulary URI
    $result = $store->query('SELECT * WHERE { <'.$uri.'> ?p ?o. } ORDER BY ?p');
    if (0 == count($result['result']['rows'])) {
        unset($miniVocabularyIndex[$uri]);
        echo PHP_EOL.'no result for URI '.$uri;
        continue;
        // TODO log no triple results for URI

    } elseif (2 <= count($result['result']['rows'])) {
        // map entries
        $map = [];
        foreach ($result['result']['rows'] as $entry) {
            if (false === isset($map[$entry['p']])) {
                $map[$entry['p']] = [];
            }

            $map[$entry['p']][] = $entry['o'];
        }

        if (
            isset($map['http://purl.org/dc/terms/modified'])
            && 0 < count($map['http://www.w3.org/ns/dcat#distribution'])
        ) {
            $modified = $map['http://purl.org/dc/terms/modified'][0];

            /** @var string|null */
            $n3FileUrl = null;

            // get related N3 file
            foreach ($map['http://www.w3.org/ns/dcat#distribution'] as $distFile) {
                if (str_contains($distFile, $modified)) {
                    $n3FileUrl = $distFile;
                    break;
                }
            }

            if (false === isEmpty($n3FileUrl) && isUrl($n3FileUrl)) {
                // latest access
                $miniVocabularyIndex[$uri]->setLatestAccess($modified.' 00:00:00');

                // latest N3 file
                $miniVocabularyIndex[$uri]->setLatestN3File($n3FileUrl);
            } else {
                unset($miniVocabularyIndex[$uri]);

                // TODO log matching N3 file not found
            }
        } else {
            unset($miniVocabularyIndex[$uri]);

            // TODO log either no dct:modified or dcat:distribution fields
        }
    } else {
        unset($miniVocabularyIndex[$uri]);

        // TODO log no valid triples
    }
}

/*
 * 5. Write temporary index to central SQLite file.
 */
storeTemporaryIndexIntoSQLiteFile($miniVocabularyIndex);

echo PHP_EOL;
